tasks_cfgs:
  nut_assembly:
    name: nut_assembly
    n_tasks: 9
    crop:
    - 20
    - 25
    - 80
    - 75
    n_per_task: 3
    task_ids:
    - 0
    - 1
    - 2
    - 3
    - 4
    - 5
    - 6
    - 7
    - 8
    skip_ids: []
    loss_mul: 1
    task_per_batch: 9
    traj_per_subtask: 100
    demo_per_subtask: 100
  door:
    name: door
    n_tasks: 4
    crop:
    - 0
    - 0
    - 0
    - 0
    n_per_task: 8
    task_ids:
    - 0
    - 1
    - 2
    - 3
    loss_mul: 1
    task_per_batch: 4
    traj_per_subtask: 100
    demo_per_subtask: 100
  drawer:
    name: drawer
    n_tasks: 8
    crop:
    - 0
    - 0
    - 0
    - 0
    n_per_task: 3
    task_ids:
    - 0
    - 1
    - 2
    - 3
    - 4
    - 5
    - 6
    - 7
    loss_mul: 1
    task_per_batch: 8
    traj_per_subtask: 100
    demo_per_subtask: 100
  button:
    name: press_button_close_after_reaching
    n_tasks: 6
    crop:
    - 10
    - 10
    - 70
    - 70
    n_per_task: 5
    task_ids:
    - 0
    - 1
    - 2
    - 3
    - 4
    - 5
    skip_ids: []
    loss_mul: 1
    task_per_batch: 6
    traj_per_subtask: 100
    demo_per_subtask: 100
  pick_place:
    name: pick_place
    n_tasks: 16
    crop:
    - 20
    - 25
    - 80
    - 75
    n_per_task: 2
    task_ids:
    - 0
    - 1
    - 2
    - 3
    - 4
    - 5
    - 6
    - 7
    - 8
    - 9
    - 10
    - 11
    - 12
    - 13
    - 14
    - 15
    skip_ids: []
    loss_mul: 1
    task_per_batch: 16
    traj_per_subtask: 100
    demo_per_subtask: 100
  stack_block:
    name: stack_block
    n_tasks: 6
    crop:
    - 20
    - 25
    - 80
    - 75
    n_per_task: 5
    task_ids:
    - 0
    - 1
    - 2
    - 3
    - 4
    - 5
    skip_ids: []
    loss_mul: 1
    task_per_batch: 6
    traj_per_subtask: 100
    demo_per_subtask: 100
  basketball:
    name: basketball
    n_tasks: 12
    crop:
    - 0
    - 0
    - 0
    - 0
    n_per_task: 3
    task_ids:
    - 0
    - 1
    - 2
    - 3
    - 4
    - 5
    - 6
    - 7
    - 8
    - 9
    - 10
    - 11
    loss_mul: 1
    task_per_batch: 12
    traj_per_subtask: 100
    demo_per_subtask: 100
finetuning_cfgs:
  panda_pick_place:
    name: panda_pick_place
    crop:
    - 20
    - 25
    - 80
    - 75
    image_channel_format: RGB
    subsample: false
  ur5e_pick_place:
    name: ur5e_pick_place
    crop:
    - 20
    - 25
    - 80
    - 75
    image_channel_format: RGB
    subsample: false
  sim_ur5e_pick_place_shifted_converted_absolute:
    name: sim_ur5e_pick_place_shifted_converted_absolute
    crop:
    - 20
    - 25
    - 80
    - 75
    image_channel_format: RGB
    subsample: false
  real_new_ur5e_pick_place_converted_absolute:
    name: real_new_ur5e_pick_place_converted_absolute
    n_tasks: 16
    crop:
    - 0
    - 30
    - 120
    - 120
    image_channel_format: BGR
    subsample: false
  asu_table_top_converted_absolute_pose:
    name: asu_table_top_converted_absolute_pose
    crop:
    - 0
    - 35
    - 0
    - 0
    image_channel_format: RGB
    subsample: false
  berkeley_autolab_ur5_converted_absolute_pose:
    name: berkeley_autolab_ur5_converted_absolute_pose
    crop:
    - 0
    - 0
    - 0
    - 0
    image_channel_format: RGB
    subsample: false
  iamlab_cmu_pickup_insert_converted_absolute_pose:
    name: iamlab_cmu_pickup_insert_converted_absolute_pose
    crop:
    - 0
    - 0
    - 0
    - 0
    image_channel_format: RGB
    subsample: false
  taco_play_converted_absolute_pose:
    name: taco_play_converted_absolute_pose
    crop:
    - 0
    - 0
    - 0
    - 0
    image_channel_format: RGB
    subsample: false
  droid_converted_absolute_pose:
    name: droid_converted_absolute_pose
    crop:
    - 0
    - 0
    - 0
    - 0
    image_channel_format: RGB
    subsample: false
debug: false
EXPERT_DATA: null
save_path: /user/frosa/multi_task_lfd/checkpoint_save_folder
wandb_log: true
project_name: rt1_sim-to-real_one_dem
log_freq: 10
val_freq: -1
print_freq: 1
save_freq: 1170
cosine_annealing: false
save_optim: true
resume: true
resume_path: rt1_sim_1_demo-Batch48
resume_step: 32670
device: 0
exp_name: rt1_sim-to-real_one_dem-Batch48
epochs: 5213
bsize: 48
vsize: 48
optimizer: AdamW
loss: ''
bb_sequence: 1
action_sequence: 1
task_names: pick_place
rollout: false
dataset_target: multi_task_il.datasets.command_encoder.finetuning_paired_dataset.FinetuningPairedDataset
couple_paths_json: /user/frosa/Multi-Task-LFD-Framework/repo/Multi-Task-LFD-Training-Framework/bashes/traj_couples
inv_mul: 0
bc_mul: 0
ce_mul: 0
pnt_mul: 0
rep_muls:
  img_byol: ${byol.mul_pre}
  attn_byol: ${byol.mul_pos}
  demo_byol: ${byol.mul_demo}
  intm_byol: ${byol.mul_intm}
  simclr_pre: ${simclr.mul_pre}
  simclr_post: ${simclr.mul_pos}
  simclr_intm: ${simclr.mul_intm}
train_cfg:
  batch_size: ${bsize}
  val_size: ${vsize}
  lr: 0.0005
  optimizer: ${optimizer}
  epochs: ${epochs}
  log_freq: ${log_freq}
  save_freq: ${save_freq}
  print_freq: ${print_freq}
  val_freq: ${val_freq}
  inv_loss_mult: ${inv_mul}
  bc_loss_mult: ${bc_mul}
  pnt_loss_mult: ${pnt_mul}
  rep_loss_muls: ${rep_muls}
  dataset: ${dataset_cfg}
  sampler: ${samplers}
  target_update_freq: 5
  early_stopping: ${early_stopping_cfg}
  weight_decay: 0.05
  lr_schedule: ReduceLROnPlateau
early_stopping_cfg:
  patience: -1
  delta: 0.001
tasks:
- name: pick_place
  n_tasks: 16
  crop:
  - 20
  - 25
  - 80
  - 75
  n_per_task: 2
  task_ids:
  - 0
  - 1
  - 2
  - 3
  - 4
  - 5
  - 6
  - 7
  - 8
  - 9
  - 10
  - 11
  - 12
  - 13
  - 14
  - 15
  skip_ids: []
  loss_mul: 1
  task_per_batch: 16
  traj_per_subtask: 100
  demo_per_subtask: 100
single_task: false
exclude_task: false
use_all_tasks: false
set_same_n: -1
limit_num_traj: -1
limit_num_demo: -1
loader_workers: 16
samplers:
  batch_size: ${bsize}
  drop_last: false
  shuffle: true
  balancing_policy: 0
val_skip: true
train_skip: true
dataset_cfg:
  _target_: ${dataset_target}
  dataset_samples_spec: ${finetuning_cfgs}
  mode: train
  jsons_folder: ${couple_paths_json}
  demo_T: 4
  obs_T: 6
  width: 180
  height: 100
  aug_twice: false
  aux_pose: true
  use_strong_augs: false
  data_augs: ${augs}
  black_list:
  - asu_table_top_converted_absolute_pose
  - berkeley_autolab_ur5_converted_absolute_pose
  - sim_ur5e_pick_place_shifted_converted_absolute
  - panda_pick_place
  - panda_pick_place_all_trajs
  select_random_frames: true
  convert_action: false
  take_first_frame: false
  non_sequential: false
  split_pick_place: false
  state_spec: ('ee_aa' 'gripper_qpos')
  load_eef_point: false
  bbs_T: 1
  perform_augs: true
  perform_scale_resize: true
  agent_name: ur5
  pick_next: false
  normalize_action: false
augs:
  old_aug: false
  brightness:
  - 0.9
  - 1.1
  contrast:
  - 0.9
  - 1.1
  saturation:
  - 0.9
  - 1.1
  hue:
  - 0.0
  - 0.0
  p: 0.1
  horizontal_flip_p: 0.1
  brightness_strong:
  - 0.875
  - 1.125
  contrast_strong:
  - 0.5
  - 1.5
  saturation_strong:
  - 0.5
  - 1.5
  hue_strong:
  - -0.05
  - 0.05
  p_strong: 0.5
  horizontal_flip_p_strong: 0.5
  null_bb: true
policy: ${rt1_video_cond}
cond_module_path: /user/frosa/multi_task_lfd/checkpoint_save_folder/cond_module_ALLBUTDROID_20epochs_RGB_weak_aug-Batch32/model_save-1012.pt
cond_module:
  height: 120
  width: 160
  demo_T: 4
  model_name: r2plus1d_18
  pretrained: true
  cond_video: true
  n_layers: 3
  demo_W: 7
  demo_H: 7
  demo_ff_dim:
  - 128
  - 64
  - 32
  demo_linear_dim:
  - 512
  - 512
  - 512
  conv_drop_dim: 3
  cond_module_model_path: ${cond_module_path}
rt1_video_cond:
  _target_: multi_task_il.models.rt1.repo.pytorch_robotics_transformer.rt1_video_cond.RT1_video_cond
  input_tensor_space:
    image:
      low: 0.0
      high: 1.0
      shape:
      - 3
      - ${dataset_cfg.height}
      - ${dataset_cfg.width}
      dtype: numpy.float32
    natural_language_embedding:
      low: float("-inf")
      high: float("inf")
      shape:
      - 512
      dtype: numpy.float32
  output_tensor_space:
    world_vector:
      low_x: -1
      low_y: -1
      low_z: -1
      high_x: 1
      high_y: 1
      high_z: 1
    rotation_delta:
      low_phi: -3.14
      low_theta: -3.14
      low_psi: -3.14
      high_phi: 3.14
      high_theta: 3.14
      high_psi: 3.14
    gripper_closedness_action:
      low: -1.0
      high: 1.0
      shape:
      - 1
      dtype: numpy.float32
  train_step_counter: 0
  vocab_size: 256
  token_embedding_size: 512
  num_layers: 1
  layer_size: 4096
  num_heads: 8
  feed_forward_size: 512
  dropout_rate: 0.1
  time_sequence_length: 6
  crop_size: 236
  use_token_learner: true
  return_attention_scores: false
  img_height: ${dataset_cfg.height}
  img_width: ${dataset_cfg.width}
  concat_target_obj_embedding: false
